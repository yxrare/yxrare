import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import warnings
warnings.filterwarnings('ignore')

# load UCI Online Retail dataset
# 数据可从 https://archive.ics.uci.edu/ml/datasets/Online+Retail 下载
df = pd.read_excel('Online Retail.xlsx')

print("===data info ===")
print(f"数据形状：{df.shape}")
print(f"\n数据类型：\n{df.dtypes}")
print(f"\n缺失值统计：\n{df.isnull().sum()}")
print(f"\n数据预览：\n{df.head()}")

# 数据质量问题识别
print("\n=== data quality ===")
print(f"重复记录数：{df.duplicated().sum()}")
print(f"CustomerID缺失：{df['CustomerID'].isnull().sum()} ({df['CustomerID'].isnull().sum()/len(df)*100:.1f}%)")
print(f"负数数量记录：{(df['Quantity'] < 0).sum()}")
print(f"零价格记录：{(df['UnitPrice'] == 0).sum()}")

# 基础统计信息
print(f"\n=== 基础统计 ===")
print(f"唯一客户数：{df['CustomerID'].nunique()}")
print(f"唯一产品数：{df['StockCode'].nunique()}")
print(f"时间跨度：{df['InvoiceDate'].min()} 至 {df['InvoiceDate'].max()}")
print(f"国家数量：{df['Country'].nunique()}")
                

# 数据清洗步骤
def clean_retail_data(df):
    """
    清洗UCI Online Retail数据集
    """
    print("原始数据形状:", df.shape)
    
    # 1. 删除CustomerID缺失的记录
    df_clean = df.dropna(subset=['CustomerID'])
    print(f"删除CustomerID缺失后: {df_clean.shape}")
    
    # 2. 删除退货记录（数量为负数）
    df_clean = df_clean[df_clean['Quantity'] > 0]
    print(f"删除退货记录后: {df_clean.shape}")
    
    # 3. 删除价格为0或负数的记录
    df_clean = df_clean[df_clean['UnitPrice'] > 0]
    print(f"删除异常价格后: {df_clean.shape}")
    
    # 4. 删除明显的测试数据（如POST、DOT等）
    test_codes = ['POST', 'DOT', 'M', 'S', 'AMAZONFEE', 'DCGSSBOY', 'DCGSSGIRL']
    df_clean = df_clean[~df_clean['StockCode'].isin(test_codes)]
    print(f"删除测试数据后: {df_clean.shape}")
    
    # 5. 删除Description缺失的记录
    df_clean = df_clean.dropna(subset=['Description'])
    print(f"删除Description缺失后: {df_clean.shape}")
    
    # 6. 处理重复记录
    df_clean = df_clean.drop_duplicates()
    print(f"删除重复记录后: {df_clean.shape}")
    
    # 7. 计算总金额
    df_clean['TotalAmount'] = df_clean['Quantity'] * df_clean['UnitPrice']
    
    # 8. 转换数据类型
    df_clean['CustomerID'] = df_clean['CustomerID'].astype(int)
    df_clean['InvoiceDate'] = pd.to_datetime(df_clean['InvoiceDate'])
    
    return df_clean

# 应用清洗函数
df_clean = clean_retail_data(df)

# 清洗后的数据概览
print("\n=== 清洗后数据概览 ===")
print(f"最终数据形状: {df_clean.shape}")
print(f"唯一客户数: {df_clean['CustomerID'].nunique()}")
print(f"数据完整性: {(1 - df_clean.isnull().sum().sum()/(df_clean.shape[0]*df_clean.shape[1]))*100:.1f}%")


# 探索性数据分析
def exploratory_analysis(df):
    """
    对清洗后的数据进行探索性分析
    """
    # 1. 销售金额分布
    print("=== 销售金额分布 ===")
    print(f"总销售额: £{df['TotalAmount'].sum():,.2f}")
    print(f"平均订单金额: £{df['TotalAmount'].mean():.2f}")
    print(f"中位数订单金额: £{df['TotalAmount'].median():.2f}")
    
    # 2. 客户消费分布
    customer_summary = df.groupby('CustomerID').agg({
        'TotalAmount': 'sum',
        'InvoiceNo': 'nunique',
        'Quantity': 'sum',
        'InvoiceDate': ['min', 'max']
    }).round(2)
    
    customer_summary.columns = ['TotalSpent', 'OrderCount', 'ItemCount', 'FirstPurchase', 'LastPurchase']
    
    print("\n=== 客户消费统计 ===")
    print(customer_summary.describe())
    
    # 3. 产品分析
    product_summary = df.groupby('StockCode').agg({
        'TotalAmount': 'sum',
        'Quantity': 'sum',
        'CustomerID': 'nunique'
    }).sort_values('TotalAmount', ascending=False)
    
    print("\n=== 热销产品TOP10 ===")
    print(product_summary.head(10))
    
    # 4. 国家分布
    country_summary = df.groupby('Country').agg({
        'TotalAmount': 'sum',
        'CustomerID': 'nunique'
    }).sort_values('TotalAmount', ascending=False)
    
    print("\n=== 国家销售分布TOP10 ===")
    print(country_summary.head(10))
    
    return customer_summary

customer_data = exploratory_analysis(df_clean)
                

# RFM特征工程
def create_rfm_features(df):
    """
    基于交易数据创建RFM特征
    """
    # 设置分析基准日期（数据集最后日期的次日）
    snapshot_date = df['InvoiceDate'].max() + pd.Timedelta(days=1)
    print(f"分析基准日期: {snapshot_date}")
    
    # 按客户聚合计算RFM
    rfm = df.groupby('CustomerID').agg({
        'InvoiceDate': lambda x: (snapshot_date - x.max()).days,  # Recency
        'InvoiceNo': 'nunique',  # Frequency  
        'TotalAmount': 'sum'  # Monetary
    }).round(2)
    
    # 重命名列
    rfm.columns = ['Recency', 'Frequency', 'Monetary']
    
    # 添加衍生特征
    rfm['AvgOrderValue'] = (df.groupby('CustomerID')['TotalAmount'].sum() / 
                           df.groupby('CustomerID')['InvoiceNo'].nunique()).round(2)
    
    # 计算购买天数跨度
    date_range = df.groupby('CustomerID')['InvoiceDate'].agg(['min', 'max'])
    rfm['DaySpan'] = (date_range['max'] - date_range['min']).dt.days
    
    # 计算购买活跃度（频次/天数跨度）
    rfm['ActivityRate'] = (rfm['Frequency'] / (rfm['DaySpan'] + 1)).round(4)
    
    # 添加国家信息
    country_info = df.groupby('CustomerID')['Country'].first()
    rfm['Country'] = country_info
    
    return rfm

# 创建RFM数据
rfm_data = create_rfm_features(df_clean)

print("=== RFM数据概览 ===")
print(f"RFM数据形状: {rfm_data.shape}")
print(f"\nRFM描述性统计:")
print(rfm_data[['Recency', 'Frequency', 'Monetary', 'AvgOrderValue']].describe())

# 检查数据分布
print(f"\n=== RFM分布检查 ===")
print(f"Recency范围: {rfm_data['Recency'].min()} - {rfm_data['Recency'].max()} 天")
print(f"Frequency范围: {rfm_data['Frequency'].min()} - {rfm_data['Frequency'].max()} 次")
print(f"Monetary范围: £{rfm_data['Monetary'].min():.2f} - £{rfm_data['Monetary'].max():,.2f}")
                
# 创建更多营销相关特征
def advanced_feature_engineering(rfm_data, df_clean):
    """
    创建高级营销分析特征
    """
    # 1. 客户生命周期特征
    rfm_data['CustomerLifetime'] = rfm_data['DaySpan'] + 1
    rfm_data['PurchaseInterval'] = rfm_data['CustomerLifetime'] / rfm_data['Frequency']
    
    # 2. 客户价值评分 (简化的CLV)
    rfm_data['CLV_Score'] = (rfm_data['Monetary'] * rfm_data['Frequency'] / 
                            (rfm_data['Recency'] + 1)).round(2)
    
    # 3. 购买行为特征
    item_stats = df_clean.groupby('CustomerID').agg({
        'Quantity': ['mean', 'std', 'max'],
        'UnitPrice': ['mean', 'std', 'max'],
        'StockCode': 'nunique'
    })
    
    item_stats.columns = ['AvgQuantity', 'StdQuantity', 'MaxQuantity',
                         'AvgPrice', 'StdPrice', 'MaxPrice', 'ProductVariety']
    
    # 4. 时间行为特征
    time_stats = df_clean.groupby('CustomerID')['InvoiceDate'].agg([
        lambda x: x.dt.hour.mode().iloc[0] if len(x.dt.hour.mode()) > 0 else 12,  # 偏好购买时间
        lambda x: x.dt.dayofweek.mode().iloc[0] if len(x.dt.dayofweek.mode()) > 0 else 1,  # 偏好购买星期
        lambda x: x.dt.month.nunique()  # 活跃月份数
    ])
    
    time_stats.columns = ['PreferredHour', 'PreferredDayOfWeek', 'ActiveMonths']
    
    # 5. 合并所有特征
    rfm_enhanced = rfm_data.join(item_stats).join(time_stats)
    
    # 6. 填充缺失值
    rfm_enhanced = rfm_enhanced.fillna(rfm_enhanced.median())
    
    return rfm_enhanced

# 创建增强特征集
rfm_enhanced = advanced_feature_engineering(rfm_data, df_clean)

print("=== 增强特征集概览 ===")
print(f"特征数量: {rfm_enhanced.shape[1]}")
print(f"数值特征: {rfm_enhanced.select_dtypes(include=[np.number]).columns.tolist()}")

# 特征相关性分析
numeric_features = rfm_enhanced.select_dtypes(include=[np.number])
correlation_matrix = numeric_features.corr()

print(f"\n=== 关键特征相关性 ===")
print("与Monetary强相关的特征:")
monetary_corr = correlation_matrix['Monetary'].abs().sort_values(ascending=False)
print(monetary_corr.head(8))
                

# 特征选择策略
def select_clustering_features(rfm_enhanced):
    """
    选择聚类的核心特征
    """
    # 核心RFM特征
    core_features = ['Recency', 'Frequency', 'Monetary']
    
    # 价值特征
    value_features = ['AvgOrderValue', 'CLV_Score']
    
    # 行为特征
    behavior_features = ['ProductVariety', 'ActivityRate', 'PurchaseInterval']
    
    # 组合最终特征集
    clustering_features = core_features + value_features + behavior_features
    
    print(f"选择的聚类特征: {clustering_features}")
    
    # 检查特征质量
    feature_data = rfm_enhanced[clustering_features]
    
    print(f"\n特征质量检查:")
    print(f"缺失值: {feature_data.isnull().sum().sum()}")
    print(f"无穷值: {np.isinf(feature_data.select_dtypes(include=[np.number])).sum().sum()}")
    
    return clustering_features, feature_data

# 选择特征
selected_features, feature_matrix = select_clustering_features(rfm_enhanced)

# 数据标准化
scaler = StandardScaler()
X_scaled = scaler.fit_transform(feature_matrix)

# 创建标准化后的DataFrame
df_scaled = pd.DataFrame(X_scaled, columns=selected_features, index=feature_matrix.index)

print(f"\n=== 标准化后数据概览 ===")
print(f"数据形状: {df_scaled.shape}")
print(f"特征均值 (应接近0): {df_scaled.mean().round(3).tolist()}")
print(f"特征标准差 (应接近1): {df_scaled.std().round(3).tolist()}")
                
📊 最优K值确定

# 肘部法则和轮廓系数分析
def find_optimal_k(X, max_k=10):
    """
    使用肘部法则和轮廓系数确定最优K值
    """
    wcss = []  # 簇内平方和
    silhouette_scores = []  # 轮廓系数
    k_range = range(2, max_k + 1)
    
    for k in k_range:
        # K-Means聚类
        kmeans = KMeans(n_clusters=k, random_state=42, n_init=10, max_iter=300)
        cluster_labels = kmeans.fit_predict(X)
        
        # 计算WCSS
        wcss.append(kmeans.inertia_)
        
        # 计算轮廓系数
        sil_score = silhouette_score(X, cluster_labels)
        silhouette_scores.append(sil_score)
        
        print(f"K={k}: WCSS={kmeans.inertia_:.2f}, Silhouette={sil_score:.3f}")
    
    # 找到肘部点 (WCSS二阶导数最大点)
    wcss_diff = np.diff(wcss)
    wcss_diff2 = np.diff(wcss_diff)
    elbow_k = np.argmax(wcss_diff2) + 3  # +3因为从k=2开始且有两次diff
    
    # 最佳轮廓系数对应的K
    best_sil_k = k_range[np.argmax(silhouette_scores)]
    
    return {
        'k_range': list(k_range),
        'wcss': wcss,
        'silhouette_scores': silhouette_scores,
        'elbow_k': elbow_k,
        'best_silhouette_k': best_sil_k,
        'best_silhouette_score': max(silhouette_scores)
    }

# 寻找最优K值
k_analysis = find_optimal_k(X_scaled, max_k=12)

print(f"\n=== K值选择结果 ===")
print(f"肘部法则建议K值: {k_analysis['elbow_k']}")
print(f"最佳轮廓系数K值: {k_analysis['best_silhouette_k']}")
print(f"最佳轮廓系数: {k_analysis['best_silhouette_score']:.3f}")

# 根据业务场景和算法结果选择K=5
optimal_k = 5
print(f"\n选择K={optimal_k}的理由:")
print("1. 轮廓系数在K=4,5时较优")
print("2. 业务上5个群体便于营销策略制定")
print("3. 符合经典的客户分层模型")
                
# 训练最终K-Means模型
final_k = 5
kmeans_final = KMeans(
    n_clusters=final_k, 
    random_state=42, 
    n_init=10, 
    max_iter=300,
    algorithm='lloyd'  # 明确指定算法
)

# 拟合模型并预测
cluster_labels = kmeans_final.fit_predict(X_scaled)

# 模型评估
final_silhouette = silhouette_score(X_scaled, cluster_labels)
final_inertia = kmeans_final.inertia_

# 将聚类结果添加到原始数据
rfm_enhanced['Cluster'] = cluster_labels

print(f"=== 最终模型结果 ===")
print(f"轮廓系数: {final_silhouette:.3f}")
print(f"簇内平方和: {final_inertia:.2f}")
print(f"聚类分布:")
cluster_distribution = pd.Series(cluster_labels).value_counts().sort_index()
for cluster, count in cluster_distribution.items():
    percentage = count / len(cluster_labels) * 100
    print(f"  Cluster {cluster}: {count:,} 客户 ({percentage:.1f}%)")

# 保存模型参数供后续使用
cluster_centers = scaler.inverse_transform(kmeans_final.cluster_centers_)
cluster_centers_df = pd.DataFrame(cluster_centers, columns=selected_features)
print(f"\n=== 聚类中心特征值 ===")
print(cluster_centers_df.round(2))
                

# 深度分析各聚类特征
def analyze_clusters(rfm_enhanced):
    """
    详细分析各个聚类的特征
    """
    cluster_summary = rfm_enhanced.groupby('Cluster').agg({
        'Recency': ['mean', 'median'],
        'Frequency': ['mean', 'median'], 
        'Monetary': ['mean', 'median'],
        'AvgOrderValue': ['mean', 'median'],
        'CLV_Score': ['mean', 'median'],
        'ProductVariety': ['mean', 'median'],
        'ActivityRate': ['mean', 'median'],
        'CustomerLifetime': ['mean', 'median']
    }).round(2)
    
    # 扁平化列名
    cluster_summary.columns = [f"{col[0]}_{col[1]}" for col in cluster_summary.columns]
    
    return cluster_summary

# 生成聚类分析报告
cluster_analysis = analyze_clusters(rfm_enhanced)
print("=== 各聚类详细特征分析 ===")
print(cluster_analysis)

# 为每个聚类生成客户价值评估
def evaluate_cluster_value(rfm_enhanced):
    """
    评估各聚类的商业价值
    """
    cluster_value = rfm_enhanced.groupby('Cluster').agg({
        'Monetary': ['sum', 'mean'],
        'Frequency': 'mean',
        'Recency': 'mean',
        'CLV_Score': 'mean',
        'ActivityRate': 'mean'
    }).round(2)
    
    # 计算各聚类占总收入比例
    total_revenue = rfm_enhanced['Monetary'].sum()
    cluster_revenue_pct = (rfm_enhanced.groupby('Cluster')['Monetary'].sum() / total_revenue * 100).round(1)
    
    # 计算客户数量占比
    total_customers = len(rfm_enhanced)
    cluster_customer_pct = (rfm_enhanced['Cluster'].value_counts().sort_index() / total_customers * 100).round(1)
    
    return cluster_value, cluster_revenue_pct, cluster_customer_pct

cluster_value, revenue_pct, customer_pct = evaluate_cluster_value(rfm_enhanced)

print(f"\n=== 聚类商业价值评估 ===")
for i in range(5):
    print(f"\nCluster {i}:")
    print(f"  客户占比: {customer_pct[i]}%")
    print(f"  收入占比: {revenue_pct[i]}%")
    print(f"  平均客户价值: £{cluster_value.loc[i, ('Monetary', 'mean')]:,.2f}")
    print(f"  平均购买频次: {cluster_value.loc[i, ('Frequency', 'mean')]:.1f}")
    print(f"  平均距今天数: {cluster_value.loc[i, ('Recency', 'mean')]:.0f}天")
                
# 生成客户分群标签字典
cluster_labels_dict = {
    0: "冠军客户 (Champions)",
    1: "忠诚客户 (Loyal Customers)", 
    2: "潜力客户 (Potential Loyalists)",
    3: "新客户 (New Customers)",
    4: "流失风险客户 (At Risk)"
}

# 应用标签
rfm_enhanced['CustomerSegment'] = rfm_enhanced['Cluster'].map(cluster_labels_dict)

# 保存分群结果
print("=== 分群结果样例 ===")
sample_results = rfm_enhanced[['Recency', 'Frequency', 'Monetary', 'Cluster', 'CustomerSegment']].head(10)
print(sample_results)

# 导出结果供后续营销使用
rfm_enhanced.to_csv('customer_segmentation_results.csv', index=True)
print(f"\n分群结果已保存到 'customer_segmentation_results.csv'")
print(f"包含 {len(rfm_enhanced)} 个客户的详细分群信息")
# 基于真实数据的营销预算分配计算
def calculate_marketing_budget(rfm_enhanced, total_budget=100000):
    """
    基于客户价值和ROI潜力分配营销预算
    """
    # 计算各群体的商业价值指标
    cluster_metrics = rfm_enhanced.groupby('Cluster').agg({
        'Monetary': ['sum', 'mean', 'count'],
        'CLV_Score': 'mean',
        'ActivityRate': 'mean'
    }).round(2)
    
    # 计算预算分配权重
    revenue_weight = 0.4  # 当前收入贡献权重
    potential_weight = 0.3  # 增长潜力权重  
    count_weight = 0.3  # 客户数量权重
    
    budget_allocation = {}
    
    for cluster in range(5):
        revenue_contribution = cluster_metrics.loc[cluster, ('Monetary', 'sum')] / rfm_enhanced['Monetary'].sum()
        customer_count_ratio = cluster_metrics.loc[cluster, ('Monetary', 'count')] / len(rfm_enhanced)
        clv_ratio = cluster_metrics.loc[cluster, ('CLV_Score', 'mean')] / rfm_enhanced['CLV_Score'].mean()
        
        # 综合权重计算
        weight = (revenue_contribution * revenue_weight + 
                 customer_count_ratio * count_weight + 
                 clv_ratio * potential_weight)
        
        budget_allocation[cluster] = weight
    
    # 归一化预算分配
    total_weight = sum(budget_allocation.values())
    budget_final = {k: (v/total_weight * total_budget) for k, v in budget_allocation.items()}
    
    return budget_final

# 计算营销预算分配
marketing_budget = calculate_marketing_budget(rfm_enhanced, total_budget=500000)

print("=== 营销预算分配建议（年度50万预算）===")
cluster_names = ["冠军客户", "忠诚客户", "潜力客户", "新客户", "流失风险"]
for i, (cluster, budget) in enumerate(marketing_budget.items()):
    percentage = budget / 500000 * 100
    print(f"{cluster_names[i]}: £{budget:,.0f} ({percentage:.1f}%)")
# 营销效果预测模型
def predict_marketing_roi(rfm_enhanced, marketing_budget):
    """
    基于历史数据预测营销活动的ROI
    """
    # 各群体的转化率和提升潜力（基于行业经验和数据分析）
    conversion_rates = {
        0: 0.85,  # 冠军客户：高留存，重复购买
        1: 0.70,  # 忠诚客户：稳定转化
        2: 0.45,  # 潜力客户：中等转化率
        3: 0.35,  # 新客户：较低转化率但量大
        4: 0.25   # 流失风险：低转化率
    }
    
    # 客单价提升潜力
    aov_increase = {
        0: 1.15,  # 冠军客户：15%提升
        1: 1.25,  # 忠诚客户：25%提升  
        2: 1.40,  # 潜力客户：40%提升
        3: 1.60,  # 新客户：60%提升
        4: 1.20   # 流失风险：20%提升
    }
    
    # 购买频次提升潜力
    frequency_increase = {
        0: 1.10,  # 冠军客户：10%提升
        1: 1.30,  # 忠诚客户：30%提升
        2: 1.80,  # 潜力客户：80%提升  
        3: 2.50,  # 新客户：150%提升
        4: 1.50   # 流失风险：50%提升
    }
    
    roi_predictions = {}
    total_predicted_revenue = 0
    total_marketing_cost = sum(marketing_budget.values())
    
    for cluster in range(5):
        cluster_data = rfm_enhanced[rfm_enhanced['Cluster'] == cluster]
        customer_count = len(cluster_data)
        avg_monetary = cluster_data['Monetary'].mean()
        avg_frequency = cluster_data['Frequency'].mean()
        
        # 计算预期收入增长
        activated_customers = customer_count * conversion_rates[cluster]
        new_aov = avg_monetary / avg_frequency * aov_increase[cluster]
        new_frequency = avg_frequency * frequency_increase[cluster]
        
        # 预测增量收入
        baseline_revenue = customer_count * avg_monetary
        predicted_revenue = activated_customers * new_aov * new_frequency
        incremental_revenue = predicted_revenue - baseline_revenue
        
        # ROI计算
        cluster_roi = incremental_revenue / marketing_budget[cluster] if marketing_budget[cluster] > 0 else 0
        
        roi_predictions[cluster] = {
            'customer_count': customer_count,
            'activated_customers': int(activated_customers),
            'baseline_revenue': baseline_revenue,
            'predicted_revenue': predicted_revenue,
            'incremental_revenue': incremental_revenue,
            'marketing_spend': marketing_budget[cluster],
            'roi': cluster_roi
        }
        
        total_predicted_revenue += incremental_revenue
    
    # 整体ROI
    overall_roi = total_predicted_revenue / total_marketing_cost
    
    return roi_predictions, overall_roi

# 执行ROI预测
roi_results, overall_roi = predict_marketing_roi(rfm_enhanced, marketing_budget)

print("=== 营销ROI预测分析 ===")
cluster_names = ["冠军客户", "忠诚客户", "潜力客户", "新客户", "流失风险"]

for i, (cluster, results) in enumerate(roi_results.items()):
    print(f"\n{cluster_names[i]} (Cluster {cluster}):")
    print(f"  目标客户数: {results['customer_count']:,}")
    print(f"  预期激活数: {results['activated_customers']:,}")
    print(f"  营销投入: £{results['marketing_spend']:,.0f}")
    print(f"  预期增量收入: £{results['incremental_revenue']:,.0f}")
    print(f"  ROI: {results['roi']:.2f}x")

print(f"\n=== 整体预测效果 ===")
print(f"总营销投入: £{sum(marketing_budget.values()):,.0f}")
print(f"预期增量收入: £{total_predicted_revenue:,.0f}")
print(f"整体ROI: {overall_roi:.2f}x")
print(f"投资回报率: {(overall_roi-1)*100:.1f}%")

# 构建营销效果监控体系
def create_monitoring_system():
    """
    建立分群体营销效果监控指标体系
    """
    monitoring_metrics = {
        'daily_metrics': {
            'conversion_rate': '各群体日转化率',
            'campaign_ctr': '营销活动点击率', 
            'revenue_per_customer': '人均贡献收入',
            'cost_per_acquisition': '获客成本'
        },
        
        'weekly_metrics': {
            'customer_upgrade_rate': '客户群体升级率',
            'retention_rate': '客户留存率',
            'average_order_value': '平均订单价值',
            'campaign_roi': '营销活动ROI'
        },
        
        'monthly_metrics': {
            'ltv_growth': '客户生命周期价值增长',
            'churn_rate': '客户流失率',
            'cross_sell_success': '交叉销售成功率',
            'customer_satisfaction': '客户满意度'
        },
        
        'alert_thresholds': {
            'conversion_rate_drop': 0.2,  # 转化率下降20%预警
            'cac_increase': 0.3,          # 获客成本上升30%预警
            'churn_rate_spike': 0.15,     # 流失率突增15%预警
            'roi_below_target': 2.0       # ROI低于2.0预警
        }
    }
    
    return monitoring_metrics

# 实时监控仪表板设计
def design_dashboard():
    """
    设计营销效果监控仪表板
    """
    dashboard_components = {
        'overview_section': [
            '整体ROI趋势图',
            '各群体收入贡献饼图', 
            '客户群体流转桑基图',
            '关键指标KPI卡片'
        ],
        
        'cluster_detail_section': [
            '各群体转化漏斗',
            '营销活动效果对比',
            '客户价值分布热力图',
            '留存率cohort分析'
        ],
        
        'alert_section': [
            '异常指标预警列表',
            '优化建议推送',
            'A/B测试结果展示',
            '竞品对比分析'
        ]
    }
    
    return dashboard_components

monitoring_system = create_monitoring_system()
dashboard_design = design_dashboard()

print("=== 监控体系设计 ===")
print("📊 日常监控指标:")
for metric, desc in monitoring_system['daily_metrics'].items():
    print(f"  • {desc} ({metric})")

print(f"\n⚠️ 预警阈值设置:")
for threshold, value in monitoring_system['alert_thresholds'].items():
    print(f"  • {threshold}: {value}")
